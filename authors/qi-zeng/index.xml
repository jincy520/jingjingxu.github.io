<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Qi Zeng on Jingjing Xu</title>
    <link>https://jingjingxupku.github.io/authors/qi-zeng/</link>
    <description>Recent content in Qi Zeng on Jingjing Xu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 31 Jul 2019 00:00:00 +0800</lastBuildDate>
    
	<atom:link href="https://jingjingxupku.github.io/authors/qi-zeng/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Asking Clarification Questions in Knowledge-Based Question Answering</title>
      <link>https://jingjingxupku.github.io/publication/emnlpclarification/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0800</pubDate>
      
      <guid>https://jingjingxupku.github.io/publication/emnlpclarification/</guid>
      <description>The ability to ask clarification questions is essential for knowledge-based question answering (KBQA) systems, especially for handling ambiguous phenomena. Despite its importance, clarification has not been well explored in current KBQA systems. Further progress requires supervised resources for training and evaluation, and powerful models for clarification-related text understanding and generation. In this paper, we construct a new clarification dataset, CLAQUA, with nearly 40K open-domain examples. The dataset supports three serial tasks: given a question, identify whether clarification is needed; if yes, generate a clarification question; then predict answers base on external user feedback.</description>
    </item>
    
    <item>
      <title>LexicalAT: Lexical-Based Adversarial Reinforcement Training for Robust Sentiment Classification</title>
      <link>https://jingjingxupku.github.io/publication/emnlplexical/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0800</pubDate>
      
      <guid>https://jingjingxupku.github.io/publication/emnlplexical/</guid>
      <description>Recent work has shown that current text classification models are fragile and sensitive to simple perturbations. In this work, we propose a novel adversarial training approach, LexicalAT, to improve the robustness of current classification models. The proposed approach consists of a generator and a classifier. The generator learns to generate examples to attack the classifier while the classifier learns to defend these attacks. Considering the diversity of attacks, the generator uses a large-scale lexical knowledge base, WordNet, to generate attacking examples by replacing some words in training examples with their synonyms (e.</description>
    </item>
    
    <item>
      <title>Review-Driven Multi-Label Music Style Classification by Exploiting Style Correlations</title>
      <link>https://jingjingxupku.github.io/publication/review/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0800</pubDate>
      
      <guid>https://jingjingxupku.github.io/publication/review/</guid>
      <description>This paper explores a new natural language processing task, review-driven multi-label music style classification. This task requires systems to identify multiple styles of music based on its reviews on websites. The biggest challenge lies in the complicated relations of music styles. To tackle this problem, we propose a novel deep learning approach to automatically learn and exploit style correlations. Experiment results show that our approach achieves large improvements over baselines on the proposed dataset.</description>
    </item>
    
    <item>
      <title>A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation</title>
      <link>https://jingjingxupku.github.io/publication/skelton/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0800</pubDate>
      
      <guid>https://jingjingxupku.github.io/publication/skelton/</guid>
      <description>Narrative story generation is a challenging problem because it demands the generated sentences with tight semantic connections, which has not been well studied by most existing generative models. To address this problem, we propose a skeleton-based model to promote the coherence of generated stories. Different from traditional models that generate a complete sentence at a stroke, the proposed model first generates the most critical phrases, called skeleton, and then expands the skeleton to a complete and fluent sentence.</description>
    </item>
    
    <item>
      <title>An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation</title>
      <link>https://jingjingxupku.github.io/publication/aematch/</link>
      <pubDate>Sat, 21 Jul 2018 00:00:00 +0800</pubDate>
      
      <guid>https://jingjingxupku.github.io/publication/aematch/</guid>
      <description>Generating semantically coherent responses is still a major challenge in dialogue generation. Different from conventional text generation tasks, the mapping between inputs and responses in conversations is more complicated, which highly demands the understanding of utterance-level semantic dependency, a relation between the whole meanings of inputs and outputs. To address this problem, we propose an Auto-Encoder Matching (AEM) model to learn such dependency. The model contains two auto-encoders and one mapping module.</description>
    </item>
    
    <item>
      <title>Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach</title>
      <link>https://jingjingxupku.github.io/publication/sentiment/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0800</pubDate>
      
      <guid>https://jingjingxupku.github.io/publication/sentiment/</guid>
      <description>The goal of sentiment-to-sentiment “translation” is to change the underlying sentiment of a sentence while keeping its content. The main challenge is the lack of parallel data. To solve this problem, we propose a cycled reinforcement learning method that enables training on unpaired data by collaboration between a neutralization module and an emotionalization module. We evaluate our approach on two review datasets, Yelp and Amazon. Experimental results show that our approach significantly outperforms the state-of-the-art systems.</description>
    </item>
    
  </channel>
</rss>